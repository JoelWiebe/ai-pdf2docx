# AI PDF to DOCX Converter (ai-pdf2docx)

This tool leverages Google's Vertex AI Gemini models to convert PDF documents, particularly academic papers, into structured Microsoft Word (.docx) files. It intelligently extracts headings (H1, H2, H3), paragraphs, and tables, applying basic styling to the output DOCX.

The process is broken into two distinct phases:
1.  **Phase 1 (PDF to JSON):** Analyzes the PDF using a Gemini model and saves the extracted structure and content as a JSON file.
2.  **Phase 2 (JSON to DOCX):** Converts the structured JSON data into a formatted .docx file.

## Features

* **AI-Powered Extraction:** Uses advanced multimodal AI (Gemini on Vertex AI) to understand document structure.
* **Two-Phase Processing:**
    * `pdf2json`: Converts PDFs to an intermediary structured JSON format.
    * `json2docx`: Converts the JSON files to styled DOCX files.
* **Structure Recognition:** Identifies and extracts:
    * Heading levels (H1, H2, H3)
    * Paragraphs
    * Tables (converted from Markdown representation)
* **Basic DOCX Styling:** Applies styles for headings and paragraphs in the generated DOCX.
* **Command-Line Interface:** Easy to use via a wrapper script `ai-pdf2docx.py`.
* **Batch Processing:** Can process multiple PDF files from a directory.
* **Configurable:** Allows selection of Gemini model, GCP project, location, and processing delay.
* **Overwrite Control:** Option to overwrite existing output files.
* **VS Code Debugging:** Includes a `launch.json` for easy debugging in Visual Studio Code.

## Prerequisites

* Python 3.8 or higher.
* A Google Cloud Platform (GCP) project with:
    * Vertex AI API enabled.
    * Billing enabled.
* Google Cloud SDK (`gcloud` CLI) installed and authenticated with Application Default Credentials:
    ```bash
    gcloud auth application-default login
    ```
* The `python-docx` and `google-cloud-aiplatform` Python libraries.

## Setup & Installation

1.  **Clone the Repository:**
    ```bash
    git clone <your-repository-url>
    cd <your-repository-name>
    ```

2.  **Create and Activate a Virtual Environment (Recommended):**
    ```bash
    python3 -m venv .venv
    source .venv/bin/activate  # On Windows: .venv\Scripts\activate
    ```

3.  **Install Dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

## Configuration

When running the scripts, you'll need to provide your Google Cloud Project ID. You can also specify the GCP location and the Gemini model to use.

* **`--project_id YOUR_GCP_PROJECT_ID`**: (Required for `pdf2json`) Your Google Cloud project ID.
* **`--location YOUR_GCP_LOCATION`**: (Optional, defaults to `global` for `pdf2json`) The GCP region for Vertex AI.
* **`--model YOUR_MODEL_NAME`**: (Optional, defaults to `gemini-2.5-pro-preview-05-06` for `pdf2json`) The Gemini model to use.

## Usage

The primary way to use the tool is via the `ai-pdf2docx.py` wrapper script, which controls the two processing phases.

### Phase 1: PDF to JSON (`pdf2json`)

This command processes all PDF files in an input directory, sends each to the Gemini model for analysis, and saves the model's raw structured output as a `.json` file in the specified output directory.

```bash
python ai-pdf2docx.py pdf2json \
  ./pdf_input_folder \
  ./json_output_folder \
  --project_id "YOUR_GCP_PROJECT_ID" \
  --location "global" \
  --model "gemini-2.5-pro-preview-05-06" \
  --delay 1 \
  # --overwrite # Uncomment to overwrite existing JSON files
  ```

* **`./pdf_input_folder`**: Directory containing your source PDF files.
* **`./json_output_folder`**: Directory where the generated JSON files will be saved.
* **`--delay 1`**: Adds a 1-second delay between API calls to help manage rate limits. Adjust as needed.

### Phase 2: JSON to DOCX (`json2docx`)
This command processes all .json files (generated by Phase 1) in an input directory and converts each into a formatted .docx file in the specified output directory.

```bash
python ai-pdf2docx.py json2docx \
  ./json_output_folder \
  ./docx_output_folder \
  # --overwrite # Uncomment to overwrite existing DOCX files
```

* `./json_output_folder`: Directory containing the JSON files from Phase 1.
* `./docx_output_folder`: Directory where the generated DOCX files will be saved.

### VS Code Debugging

This workspace includes a `.vscode/launch.json` file with pre-configured launch profiles for debugging both the `pdf2json` and `json2docx` phases using the `ai-pdf2docx.py` wrapper.

1.  Open the project folder in VS Code.
2.  Go to the "Run and Debug" view (Ctrl+Shift+D or Cmd+Shift+D).
3.  Open the `.vscode/launch.json` file and **update the placeholder paths and your GCP Project ID** in the `args` section for each configuration.
4.  Select the desired launch configuration (e.g., "AI-PDF2DOCX: PDF to JSON") from the dropdown.
5.  Set breakpoints in the Python code and start debugging (F5).

### Important Considerations & Warnings

#### Vertex AI Costs
* **Using the Vertex AI Gemini models will incur costs on your Google Cloud Platform account.** Costs are typically based on the amount of data processed (e.g., number of characters or tokens in input and output) and the specific model used.
* Please review the official [Vertex AI Pricing page](https://cloud.google.com/vertex-ai/pricing) for the most up-to-date information before processing a large number of documents.
* Monitor your GCP billing dashboard regularly.

#### Computation Time
* The PDF to JSON conversion (Phase 1) can be time-consuming, especially for large and complex documents.
* **Estimate:** A 20-page research paper PDF might take approximately **6 minutes** for the `pdf2json` phase. This is a rough estimate and can vary significantly based on:
    * PDF complexity (scanned vs. text-based, number of images, intricate layouts).
    * The specific Gemini model version used.
    * Current Vertex AI service load.
    * Document length and content density.
* The `json2docx` phase (Phase 2) is generally much faster as it involves local processing.

#### API Rate Limits
* Google Cloud enforces API rate limits. If you are processing a very large batch of PDFs, you might encounter these limits.
* The `pdf2json` command includes a `--delay` option (e.g., `--delay 1` for a 1-second pause between files) which can help mitigate this. Adjust the delay as needed.

#### Accuracy & Output Quality
* AI-based document understanding is a complex task. While Gemini models are powerful, the accuracy of extracted headings, paragraphs, and especially tables, may vary.
* **Always review the generated DOCX files for accuracy and completeness.**
* **JSON Output (Phase 1):** The script saves the raw text output from the Gemini model as a `.json` file. While the prompt strongly requests valid JSON, there's a small chance the model might produce slightly malformed JSON for highly complex or unusual inputs. Phase 2 will report errors if it cannot parse a JSON file. You may need to manually inspect and correct such files.
* **Table Conversion:** Tables are extracted as Markdown and then converted to DOCX tables. Very complex tables (e.g., with merged cells or highly irregular structures) might not be rendered perfectly.

## Error Handling and Resuming Processing (`ai-pdf2docx`)

The `ai-pdf2docx` tool processes documents in two main phases: `pdf2json` (converting PDF to a structured JSON representation via an LLM) and `json2docx` (converting the JSON to a DOCX file). Errors can occur in either phase.

The script (especially if using an `ai-pdf2docx.py` wrapper script with subcommands for `pdf2json` and `json2docx`) is generally designed to process files in a batch. If an error occurs with a specific file, it may skip that file and continue with others, or halt depending on the severity and the script's error handling for fatal issues. The console output logs are your primary guide for identifying problematic files.

Here are some common errors and how to address them:

### 1. Errors During Phase 1 (`pdf2json` - PDF to JSON Conversion)

This phase involves the LLM (e.g., Gemini) parsing the PDF and generating a structured JSON output.

**Error Example:**
"Error calling Gemini API… Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details… Failed to get structured data for ./pdf_input_folder/your_document_name.pdf. Skipping JSON file creation."
```
**Possible Causes and Solutions:**

* **PDF Complexity or Issues:**
    * Very complex PDFs (e.g., intricate layouts, scanned documents requiring high-quality OCR by the LLM, non-standard fonts, heavy vector graphics) or PDFs with issues like corrupted embedded elements or security restrictions can sometimes cause the LLM to struggle or take a very long time. This might lead to timeouts or other API errors.
    * **Solutions:**
        * **Try obtaining a cleaner, more standard, or text-based version of the PDF if possible.**
        * For scanned PDFs, ensure they are of high quality if the LLM is expected to perform OCR.
        * If a specific PDF consistently fails, move it to a separate folder (e.g., `input_docs/pdf2json_failed/`) and attempt to process it individually later, perhaps with different settings or after inspection.

* **API Rate Limits / Quotas ("Resource exhausted"):**
    * This HTTP 429 error usually means you're making too many requests to the Vertex AI API in a short period, or you've hit a specific quota limit for your project.
    * **Solutions:**
        * **Wait and Retry:** As the message suggests, try running the script again later.
        * **Check Quotas:** Review your Vertex AI quotas in the Google Cloud Console to see if you are hitting any limits (e.g., requests per minute for the specific model). You may need to request an increase.
        * **Use a `--delay` flag (if available):** If your `ai-pdf2docx.py` script processes many PDFs in a batch for the `pdf2json` command, a delay option (e.g., `--delay 1` or `--delay 2` to add a pause between processing each PDF) can help avoid requests-per-minute limits.
        * **Reduce Concurrent Processing:** If you are running multiple instances of the script, reduce the number running simultaneously.

### 2. Errors During Phase 2 (`json2docx` - JSON to DOCX Conversion)

This phase reads the `.json` file (created by `pdf2json`) and uses its structure to generate a `.docx` file.

**Error Example (when `json2docx` tries to load a malformed JSON):**
"Error decoding JSON from file for ./json_input_folder/your_document_name.json: Unterminated string starting at: line 925 column 18 (char 131084)"

**Possible Causes and Solutions:**

* **Truncated or Malformed JSON from Phase 1 (`pdf2json`):**
    * This is the most common cause. The LLM, during the `pdf2json` phase, may have hit its `max_output_tokens` limit while generating the structured JSON for a very long or complex PDF. This results in an incomplete (truncated) JSON file that cannot be parsed by `json.loads()` in Phase 2.
    * **Solutions:**
        1.  **Increase Output Token Limit for `pdf2json`:**
            * Modify the `GENERATION_CONFIGURATION` (likely in a `config.py` or passed as parameters) for the `pdf2json` phase to increase `max_output_tokens`. This gives the LLM more room to generate the complete JSON for large documents.
        2.  **Split the Original PDF:**
            * For exceptionally long or complex PDFs that consistently result in truncated JSON, manually split the original PDF into smaller, more manageable documents (e.g., Part1.pdf, Part2.pdf).
            * Run `ai-pdf2docx pdf2json` on these smaller PDF parts separately. This will generate multiple JSON files.
            * Then, run `ai-pdf2docx json2docx` on these JSON files, which will produce multiple DOCX files. You might need to manually combine the DOCX files later if a single final document is required.
        3.  **Attempt Manual JSON Repair (Advanced & Risky):**
            * "If incomplete json is part of the References list, just close the json (e.g., add closing `]` and `}` syntax) (as we don’t need all of the references for this project)."
            * This approach is for users comfortable editing JSON. If the JSON is truncated towards the end (e.g., within a list of references that are not critical for the DOCX structure), you might be able to open the `.json` file in a text editor and manually add the necessary closing brackets (`]`), braces (`}`), and commas to make it syntactically valid.
            * **Caution:** Incorrect manual edits can further corrupt the JSON. Always work on a copy. Use an online JSON validator to check your edits before re-running the `json2docx` phase. This is best for minor fixes near the end of the file.

### General Resuming Strategy for `ai-pdf2docx`

* **Identify Problematic Files:** Note which PDF (for `pdf2json` errors) or JSON file (for `json2docx` errors) caused the script to report an error or skip a file.
* **Isolate:** Move the problematic file(s) to a temporary "pending\_review" or "failed" subfolder.
* **Re-run:**
    * The `ai-pdf2docx.py` script (or its sub-phases) might have an `--overwrite` flag or similar logic. If **not** using overwrite, the script should ideally skip files for which the output already exists (e.g., if `output.json` exists, `pdf2json` for `input.pdf` might skip).
    * By moving the problematic file, re-running the script on the original input directory should allow it to process any remaining files that were not processed in the previous run.
* **Address and Retry Problematic Files:**
    * Once the main batch is processed, focus on the isolated problematic files.
    * Apply the specific solutions outlined above (e.g., increase token limits for `pdf2json` when retrying that PDF, split the PDF, or attempt to repair a truncated JSON for `json2docx`).
    * After attempting a fix, move the file back to the appropriate input directory and run the relevant phase again, possibly focused only on that single file to observe its behavior more closely.

By following these error handling and resuming guidelines, you can manage issues more effectively when processing batches of documents with the `ai-pdf2docx` tool.

### File Structure

* `ai-pdf2docx.py`: Main wrapper script and command-line interface.
* `phase1_pdf_to_json.py`: Contains the logic for PDF analysis and communication with Vertex AI.
* `phase2_json_to_docx.py`: Contains the logic for converting structured JSON to DOCX files.
* `.vscode/launch.json`: VS Code debugger configurations.
* `requirements.txt`: Python dependencies.
* `README.md`: This file.
